"""Add lifecycle analysis cells to the notebook AFTER the existing pipeline cells
but BEFORE the final download cell (cell 75)."""
import json, copy

NB_PATH = "SHARE_Fairness_Benchmark_v12__2___1_ (1).ipynb"

with open(NB_PATH, "r") as f:
    nb = json.load(f)

# Template for a new cell
def make_cell(cell_type, source_lines):
    return {
        "cell_type": cell_type,
        "metadata": {},
        "source": source_lines,
        **({"outputs": [], "execution_count": None} if cell_type == "code" else {}),
    }

new_cells = []

# ── Markdown: Section header ─────────────────────────────────────────
new_cells.append(make_cell("markdown", [
    "---\n",
    "## Fairness Lifecycle Analysis\n",
    "The following cells implement the **lifecycle evaluation framework**.\n",
    "They trace 26 methods through successive deployment stages and quantify clinical impact for survivors.\n",
    "\n",
    "**Important**: These cells read from `tables/` CSVs produced by the main pipeline above. ",
    "Do NOT re-run the pipeline cells; just run these new cells."
]))

# ── Code: Lifecycle Survival Funnel ──────────────────────────────────
new_cells.append(make_cell("markdown", [
    "### Fig 6: Lifecycle Survival Funnel\n",
    "Shows progressive elimination of 26 methods through deployment stages.\n",
    "This is the paper's **signature figure**."
]))

new_cells.append(make_cell("code", [
    '# ============================================================\n',
    '# FIG 6 – Lifecycle Survival Funnel\n',
    '# ============================================================\n',
    'import pandas as pd, numpy as np, matplotlib.pyplot as plt, matplotlib.patches as mpatches\n',
    'from pathlib import Path\n',
    '\n',
    'OUT = Path("fairness_output")\n',
    'OUT.mkdir(exist_ok=True)\n',
    '\n',
    'full = pd.read_csv("tables/full_results.csv")\n',
    'deploy = pd.read_csv("tables/deployability_contract.csv")\n',
    '\n',
    '# ── Baselines per outcome ──\n',
    'baselines = full[full["Method"] == "BASELINE"].set_index("Outcome")\n',
    'methods = full[full["Method"] != "BASELINE"].copy()\n',
    '\n',
    'outcomes = ["EUROD", "LS", "CASP", "SRH"]\n',
    'all_methods = sorted(methods["Method"].unique())\n',
    'n_start = len(all_methods)  # 26\n',
    '\n',
    '# ── Stage 1: Effectiveness (% reduction > 0 on >= 3 of 4 outcomes) ──\n',
    'def check_effectiveness(m):\n',
    '    rows = methods[methods["Method"] == m]\n',
    '    pos = sum(rows["Pct_Reduction"] > 0)\n',
    '    return pos >= 3\n',
    '\n',
    'stage1 = [m for m in all_methods if check_effectiveness(m)]\n',
    '\n',
    '# ── Stage 2: Deployability (Tier 1 = no A at inference) ──\n',
    'tier1 = set(deploy[deploy["Deployable"] == "Yes"]["Method"])\n',  # Note: using the Deployable column from deployability_contract
    'stage2 = [m for m in stage1 if m in tier1]\n',
    '\n',
    '# ── Stage 3: Accuracy (AUROC drop <= 0.03 on ALL outcomes) ──\n',
    'def check_accuracy(m):\n',
    '    for oc in outcomes:\n',
    '        bl = baselines.loc[oc, "AUROC_mean"]\n',
    '        row = methods[(methods["Method"] == m) & (methods["Outcome"] == oc)]\n',
    '        if row.empty:\n',
    '            return False\n',
    '        if bl - row.iloc[0]["AUROC_mean"] > 0.03:\n',
    '            return False\n',
    '    return True\n',
    '\n',
    'stage3 = [m for m in stage2 if check_accuracy(m)]\n',
    '\n',
    '# ── Stage 4: Stability (sign >= 4/5 on ALL outcomes) ──\n',
    'def check_stability(m):\n',
    '    for oc in outcomes:\n',
    '        row = methods[(methods["Method"] == m) & (methods["Outcome"] == oc)]\n',
    '        if row.empty:\n',
    '            return False\n',
    '        if row.iloc[0]["Sign_improved"] < 4:\n',
    '            return False\n',
    '    return True\n',
    '\n',
    'stage4 = [m for m in stage3 if check_stability(m)]\n',
    '\n',
    '# ── Stage 5: Fairness threshold (>= 25% reduction on ALL outcomes) ──\n',
    'def check_fairness(m):\n',
    '    for oc in outcomes:\n',
    '        row = methods[(methods["Method"] == m) & (methods["Outcome"] == oc)]\n',
    '        if row.empty:\n',
    '            return False\n',
    '        if row.iloc[0]["Pct_Reduction"] < 25:\n',
    '            return False\n',
    '    return True\n',
    '\n',
    'stage5 = [m for m in stage4 if check_fairness(m)]\n',
    '\n',
    '# ── Print results ──\n',
    'stages = [\n',
    '    ("All methods", n_start),\n',
    '    ("Effectiveness\\n(reduces disparity)", len(stage1)),\n',
    '    ("Deployability\\n(no A at inference)", len(stage2)),\n',
    '    ("Accuracy\\n(AUROC drop ≤ 3pp)", len(stage3)),\n',
    '    ("Stability\\n(sign ≥ 4/5)", len(stage4)),\n',
    '    ("Fairness\\n(≥ 25% reduction)", len(stage5)),\n',
    ']\n',
    '\n',
    'print("LIFECYCLE FILTER RESULTS")\n',
    'print("=" * 50)\n',
    'for name, n in stages:\n',
    '    print(f"  {name.replace(chr(10), \" \"):40s} → {n} methods")\n',
    'print(f"\\nSurvivors: {stage5}")\n',
    '\n',
    '# ── Plot the funnel ──\n',
    'fig, ax = plt.subplots(figsize=(10, 7))\n',
    '\n',
    'labels = [s[0] for s in stages]\n',
    'counts = [s[1] for s in stages]\n',
    'colors = ["#4A90D9", "#5BA0E0", "#7CB5E8", "#A8CCF0", "#C4DCF5", "#2E8B57"]\n',
    '\n',
    'max_w = 0.9\n',
    'y_positions = list(range(len(stages) - 1, -1, -1))\n',
    '\n',
    'for i, (label, count) in enumerate(zip(labels, counts)):\n',
    '    w = max_w * (count / counts[0]) if counts[0] > 0 else 0.1\n',
    '    w = max(w, 0.12)  # minimum width\n',
    '    rect = mpatches.FancyBboxPatch(\n',
    '        (0.5 - w/2, y_positions[i] - 0.35), w, 0.7,\n',
    '        boxstyle="round,pad=0.05", facecolor=colors[i], edgecolor="white", linewidth=2\n',
    '    )\n',
    '    ax.add_patch(rect)\n',
    '    ax.text(0.5, y_positions[i], f"{count}",\n',
    '            ha="center", va="center", fontsize=22, fontweight="bold", color="white")\n',
    '    ax.text(-0.05, y_positions[i], label.replace("\\n", " \"),\n',
    '            ha="right", va="center", fontsize=10, color="#333")\n',
    '    # Arrow between stages\n',
    '    if i < len(stages) - 1:\n',
    '        eliminated = counts[i] - counts[i+1]\n',
    '        if eliminated > 0:\n',
    '            ax.annotate(f"−{eliminated}", xy=(0.5, y_positions[i] - 0.42),\n',
    '                       fontsize=9, ha="center", color="#CC3333", fontweight="bold")\n',
    '\n',
    'ax.set_xlim(-0.6, 1.1)\n',
    'ax.set_ylim(-0.8, len(stages) - 0.3)\n',
    'ax.set_title("Fairness Lifecycle: From 26 Methods to Survivors",\n',
    '             fontsize=14, fontweight="bold", pad=15)\n',
    'ax.axis("off")\n',
    'plt.tight_layout()\n',
    'plt.savefig(OUT / "lifecycle_funnel.png", dpi=300, bbox_inches="tight")\n',
    'plt.savefig(OUT / "lifecycle_funnel.pdf", bbox_inches="tight")\n',
    'plt.show()\n',
    'print(f"Saved: {OUT}/lifecycle_funnel.png")\n',
]))

# ── Code: Lifecycle Survival Table ───────────────────────────────────
new_cells.append(make_cell("markdown", [
    "### Table: Lifecycle Survival Matrix\n",
    "Pass/Fail status for every method at every lifecycle stage."
]))

new_cells.append(make_cell("code", [
    '# ============================================================\n',
    '# LIFECYCLE SURVIVAL TABLE\n',
    '# ============================================================\n',
    'import pandas as pd\n',
    '\n',
    'full = pd.read_csv("tables/full_results.csv")\n',
    'deploy_df = pd.read_csv("tables/deployability_contract.csv")\n',
    'baselines = full[full["Method"] == "BASELINE"].set_index("Outcome")\n',
    'methods_df = full[full["Method"] != "BASELINE"].copy()\n',
    'outcomes = ["EUROD", "LS", "CASP", "SRH"]\n',
    'all_methods = sorted(methods_df["Method"].unique())\n',
    'tier1_set = set(deploy_df[deploy_df["Deployable"] == "Yes"]["Method"])\n',
    '\n',
    'rows = []\n',
    'for m in all_methods:\n',
    '    mdata = methods_df[methods_df["Method"] == m]\n',
    '    cat = mdata.iloc[0]["Category"]\n',
    '\n',
    '    # Effectiveness\n',
    '    eff = sum(mdata.set_index("Outcome").reindex(outcomes)["Pct_Reduction"] > 0) >= 3\n',
    '\n',
    '    # Deployability\n',
    '    dep = m in tier1_set\n',
    '\n',
    '    # Accuracy\n',
    '    acc = True\n',
    '    for oc in outcomes:\n',
    '        bl = baselines.loc[oc, "AUROC_mean"]\n',
    '        r = mdata[mdata["Outcome"] == oc]\n',
    '        if not r.empty and bl - r.iloc[0]["AUROC_mean"] > 0.03:\n',
    '            acc = False\n',
    '\n',
    '    # Stability\n',
    '    stab = True\n',
    '    for oc in outcomes:\n',
    '        r = mdata[mdata["Outcome"] == oc]\n',
    '        if not r.empty and r.iloc[0]["Sign_improved"] < 4:\n',
    '            stab = False\n',
    '\n',
    '    # Fairness (>=25% reduction all outcomes)\n',
    '    fair = True\n',
    '    for oc in outcomes:\n',
    '        r = mdata[mdata["Outcome"] == oc]\n',
    '        if not r.empty and r.iloc[0]["Pct_Reduction"] < 25:\n',
    '            fair = False\n',
    '\n',
    '    survives = eff and dep and acc and stab and fair\n',
    '    rows.append({\n',
    '        "Method": m,\n',
    '        "Category": cat,\n',
    '        "Effective": "Pass" if eff else "FAIL",\n',
    '        "Deployable": "Pass" if dep else "FAIL",\n',
    '        "Accuracy": "Pass" if acc else "FAIL",\n',
    '        "Stable": "Pass" if stab else "FAIL",\n',
    '        "Fair_25pct": "Pass" if fair else "FAIL",\n',
    '        "SURVIVES": "YES" if survives else "no",\n',
    '    })\n',
    '\n',
    'survival_df = pd.DataFrame(rows)\n',
    'survival_df = survival_df.sort_values(["SURVIVES", "Category", "Method"],\n',
    '                                       ascending=[False, True, True])\n',
    '\n',
    '# Save\n',
    'survival_df.to_csv("tables/lifecycle_survival_matrix.csv", index=False)\n',
    'print("LIFECYCLE SURVIVAL MATRIX")\n',
    'print("=" * 90)\n',
    'print(survival_df.to_string(index=False))\n',
    'print(f"\\nSurvivors: {list(survival_df[survival_df.SURVIVES == \\\"YES\\\"][\\\"Method\\\"])}")\n',
]))

# ── Code: Clinical Impact Estimation ─────────────────────────────────
new_cells.append(make_cell("markdown", [
    "### Fig 7: Clinical Impact Estimation\n",
    "Translates TPR gap reductions into additional correct identifications per screening wave."
]))

new_cells.append(make_cell("code", [
    '# ============================================================\n',
    '# FIG 7 – Clinical Impact: Additional Correct Identifications\n',
    '# ============================================================\n',
    'import pandas as pd, numpy as np, matplotlib.pyplot as plt\n',
    'from pathlib import Path\n',
    '\n',
    'OUT = Path("fairness_output")\n',
    'full = pd.read_csv("tables/full_results.csv")\n',
    'baselines = full[full["Method"] == "BASELINE"].set_index("Outcome")\n',
    '\n',
    '# Q5 sizes and prevalence rates from Table 1\n',
    'N_Q5 = 10123\n',
    'prevalence_Q5 = {"EUROD": 0.210, "LS": 0.198, "CASP": 0.168, "SRH": 0.253}\n',
    'outcome_labels = {"EUROD": "Depression\\n(EURO-D)", "LS": "Life\\nSatisfaction",\n',
    '                  "CASP": "Quality of\\nLife (CASP)", "SRH": "Self-Rated\\nHealth"}\n',
    '\n',
    '# Survivors from lifecycle filter\n',
    'survivors = ["ExpGrad_TPR", "ExpGrad_EO", "Reweighing"]\n',
    'colors_s = {"ExpGrad_TPR": "#2E8B57", "ExpGrad_EO": "#4A90D9", "Reweighing": "#F5A623"}\n',
    '\n',
    'outcomes = ["EUROD", "LS", "CASP", "SRH"]\n',
    '\n',
    'fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n',
    '\n',
    '# ── Panel A: Additional correct identifications ──\n',
    'ax = axes[0]\n',
    'x = np.arange(len(outcomes))\n',
    'width = 0.25\n',
    '\n',
    'total_all = {}\n',
    'for si, surv in enumerate(survivors):\n',
    '    impacts = []\n',
    '    for oc in outcomes:\n',
    '        bl_gap = baselines.loc[oc, "TPR_gap_mean"]\n',
    '        row = full[(full["Method"] == surv) & (full["Outcome"] == oc)]\n',
    '        m_gap = row.iloc[0]["TPR_gap_mean"]\n',
    '        n_pos = N_Q5 * prevalence_Q5[oc]\n',
    '        additional = (bl_gap - m_gap) * n_pos\n',
    '        impacts.append(max(additional, 0))\n',
    '    total_all[surv] = sum(impacts)\n',
    '    bars = ax.bar(x + si * width, impacts, width, label=surv,\n',
    '                  color=colors_s[surv], edgecolor="white")\n',
    '    for bar, val in zip(bars, impacts):\n',
    '        if val > 10:\n',
    '            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 8,\n',
    '                    f"{val:.0f}", ha="center", va="bottom", fontsize=8)\n',
    '\n',
    'ax.set_xticks(x + width)\n',
    'ax.set_xticklabels([outcome_labels[oc] for oc in outcomes], fontsize=9)\n',
    'ax.set_ylabel("Additional correct identifications (Q5)", fontsize=10)\n',
    'ax.set_title("A. Per-Outcome Clinical Impact", fontsize=12, fontweight="bold")\n',
    'ax.legend(fontsize=9)\n',
    'ax.spines["top"].set_visible(False)\n',
    'ax.spines["right"].set_visible(False)\n',
    '\n',
    '# ── Panel B: Total across outcomes ──\n',
    'ax2 = axes[1]\n',
    'methods_sorted = sorted(total_all.keys(), key=lambda m: total_all[m], reverse=True)\n',
    'vals = [total_all[m] for m in methods_sorted]\n',
    'cols = [colors_s[m] for m in methods_sorted]\n',
    'bars2 = ax2.barh(methods_sorted, vals, color=cols, edgecolor="white", height=0.5)\n',
    'for bar, val in zip(bars2, vals):\n',
    '    ax2.text(bar.get_width() + 20, bar.get_y() + bar.get_height()/2,\n',
    '             f"{val:.0f}", ha="left", va="center", fontsize=11, fontweight="bold")\n',
    'ax2.set_xlabel("Total additional identifications across 4 outcomes", fontsize=10)\n',
    'ax2.set_title("B. Combined Clinical Impact (Q5)", fontsize=12, fontweight="bold")\n',
    'ax2.spines["top"].set_visible(False)\n',
    'ax2.spines["right"].set_visible(False)\n',
    '\n',
    'plt.tight_layout()\n',
    'plt.savefig(OUT / "clinical_impact.png", dpi=300, bbox_inches="tight")\n',
    'plt.savefig(OUT / "clinical_impact.pdf", bbox_inches="tight")\n',
    'plt.show()\n',
    '\n',
    'print("\\nCLINICAL IMPACT SUMMARY")\n',
    'print("=" * 50)\n',
    'for m in methods_sorted:\n',
    '    print(f"  {m:20s}: {total_all[m]:.0f} additional identifications")\n',
    'print(f"\\nSaved: {OUT}/clinical_impact.png")\n',
]))

# ── Code: Deployability Cliff Figure ─────────────────────────────────
new_cells.append(make_cell("markdown", [
    "### Fig 8: The Deployability Cliff\n",
    "Proportion of deployable methods by category. Highlights that **0/6 post-processing** methods are deployable."
]))

new_cells.append(make_cell("code", [
    '# ============================================================\n',
    '# FIG 8 – Deployability Cliff by Category\n',
    '# ============================================================\n',
    'import pandas as pd, matplotlib.pyplot as plt\n',
    'from pathlib import Path\n',
    '\n',
    'OUT = Path("fairness_output")\n',
    'deploy_df = pd.read_csv("tables/deployability_contract.csv")\n',
    '\n',
    'categories = ["Pre-processing", "In-processing", "Post-processing", "Augmentation"]\n',
    'dep_yes, dep_no = [], []\n',
    '\n',
    'for cat in categories:\n',
    '    sub = deploy_df[deploy_df["Category"] == cat]\n',
    '    y = (sub["Deployable"] == "Yes").sum()\n',
    '    n = (sub["Deployable"] == "No").sum()\n',
    '    dep_yes.append(y)\n',
    '    dep_no.append(n)\n',
    '\n',
    'fig, ax = plt.subplots(figsize=(8, 5))\n',
    'x = range(len(categories))\n',
    'bars1 = ax.bar(x, dep_yes, 0.6, label="Deployable (Tier 1)", color="#2E8B57", edgecolor="white")\n',
    'bars2 = ax.bar(x, dep_no, 0.6, bottom=dep_yes, label="Non-deployable (Tier 2/3)",\n',
    '               color="#CC3333", edgecolor="white", alpha=0.8)\n',
    '\n',
    'for i, (y, n) in enumerate(zip(dep_yes, dep_no)):\n',
    '    total = y + n\n',
    '    pct = y / total * 100 if total > 0 else 0\n',
    '    ax.text(i, total + 0.2, f"{y}/{total}\\n({pct:.0f}%)",\n',
    '            ha="center", va="bottom", fontsize=10, fontweight="bold")\n',
    '\n',
    '# Highlight the post-processing cliff\n',
    'ax.annotate("DEPLOYABILITY\\nCLIFF", xy=(2, 0.3), fontsize=11,\n',
    '            fontweight="bold", color="white", ha="center")\n',
    '\n',
    'ax.set_xticks(x)\n',
    'ax.set_xticklabels(categories, fontsize=10)\n',
    'ax.set_ylabel("Number of methods", fontsize=11)\n',
    'ax.set_title("The Deployability Cliff: Post-Processing Methods Fail Deployment",\n',
    '             fontsize=12, fontweight="bold")\n',
    'ax.legend(loc="upper left", fontsize=9)\n',
    'ax.spines["top"].set_visible(False)\n',
    'ax.spines["right"].set_visible(False)\n',
    'ax.set_ylim(0, max(y + n for y, n in zip(dep_yes, dep_no)) + 3)\n',
    '\n',
    'plt.tight_layout()\n',
    'plt.savefig(OUT / "deployability_cliff.png", dpi=300, bbox_inches="tight")\n',
    'plt.savefig(OUT / "deployability_cliff.pdf", bbox_inches="tight")\n',
    'plt.show()\n',
    'print(f"Saved: {OUT}/deployability_cliff.png")\n',
]))

# ── Code: Lifecycle Summary Statistics ───────────────────────────────
new_cells.append(make_cell("markdown", [
    "### Lifecycle Summary Statistics\n",
    "Key numbers for the manuscript text."
]))

new_cells.append(make_cell("code", [
    '# ============================================================\n',
    '# LIFECYCLE SUMMARY – Key numbers for manuscript\n',
    '# ============================================================\n',
    'import pandas as pd\n',
    '\n',
    'full = pd.read_csv("tables/full_results.csv")\n',
    'baselines = full[full["Method"] == "BASELINE"].set_index("Outcome")\n',
    'outcomes = ["EUROD", "LS", "CASP", "SRH"]\n',
    '\n',
    'print("=" * 70)\n',
    'print("KEY LIFECYCLE STATISTICS FOR MANUSCRIPT")\n',
    'print("=" * 70)\n',
    '\n',
    'print("\\n1. BASELINE DISPARITIES")\n',
    'for oc in outcomes:\n',
    '    gap = baselines.loc[oc, "TPR_gap_mean"]\n',
    '    auroc = baselines.loc[oc, "AUROC_mean"]\n',
    '    print(f"   {oc}: TPR gap = {gap:.3f} ({gap*100:.1f} pp), AUROC = {auroc:.3f}")\n',
    '\n',
    'print("\\n2. SURVIVOR PERFORMANCE")\n',
    'for m in ["ExpGrad_TPR", "ExpGrad_EO", "Reweighing"]:\n',
    '    print(f"\\n   {m}:")\n',
    '    for oc in outcomes:\n',
    '        row = full[(full["Method"] == m) & (full["Outcome"] == oc)].iloc[0]\n',
    '        bl = baselines.loc[oc]\n',
    '        print(f"     {oc}: TPR gap {row.TPR_gap_mean:.3f} "\n',
    '              f"({row.Pct_Reduction:.1f}% red), "\n',
    '              f"AUROC {row.AUROC_mean:.3f} "\n',
    '              f"(drop {bl.AUROC_mean - row.AUROC_mean:.3f}), "\n',
    '              f"sign {int(row.Sign_improved)}/5")\n',
    '\n',
    'print("\\n3. DEPLOYABILITY CLIFF")\n',
    'deploy = pd.read_csv("tables/deployability_contract.csv")\n',
    'for cat in ["Pre-processing", "In-processing", "Post-processing", "Augmentation"]:\n',
    '    sub = deploy[deploy["Category"] == cat]\n',
    '    y = (sub["Deployable"] == "Yes").sum()\n',
    '    t = len(sub)\n',
    '    print(f"   {cat}: {y}/{t} deployable ({y/t*100:.0f}%)")\n',
    '\n',
    'print("\\n4. CLINICAL IMPACT (Q5, N=10,123)")\n',
    'prev_q5 = {"EUROD": 0.210, "LS": 0.198, "CASP": 0.168, "SRH": 0.253}\n',
    'total = 0\n',
    'for oc in outcomes:\n',
    '    bl_gap = baselines.loc[oc, "TPR_gap_mean"]\n',
    '    eg = full[(full["Method"] == "ExpGrad_TPR") & (full["Outcome"] == oc)].iloc[0]\n',
    '    n_pos = 10123 * prev_q5[oc]\n',
    '    add = (bl_gap - eg.TPR_gap_mean) * n_pos\n',
    '    total += add\n',
    '    print(f"   {oc}: {add:.0f} additional identifications")\n',
    'print(f"   TOTAL: {total:.0f}")\n',
    'print("=" * 70)\n',
]))

# ── Insert new cells before the final download cell (index 75) ──
insert_pos = len(nb["cells"]) - 1  # Before last cell
nb["cells"] = nb["cells"][:insert_pos] + new_cells + nb["cells"][insert_pos:]

with open(NB_PATH, "w") as f:
    json.dump(nb, f, indent=1)

print(f"Added {len(new_cells)} cells to notebook at position {insert_pos}")
print(f"Total cells now: {len(nb['cells'])}")
